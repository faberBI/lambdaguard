<p align="center">
  <img src="docs/logo.png" alt="Î»-Guard" width="160"/>
</p>

<p align="center">
<strong>Overfitting detection for Gradient Boosting</strong> â€” <em>no validation set required</em><br>
<i>Detect the moment when your model stops learning signal and starts memorizing structure.</i>
</p>

<p align="center">
  <a href="https://github.com/faberBI/lambdaguard/actions/workflows/tests.yml">
    <img src="https://img.shields.io/github/actions/workflow/status/faberBI/lambdaguard/tests.yml?branch=main&logo=github" alt="Tests Status">
  </a>
  <a href="https://coveralls.io/github/faberBI/lambdaguard">
    <img src="https://img.shields.io/coveralls/github/faberBI/lambdaguard/main.svg" alt="Coverage Status">
  </a>
  <a href="https://pypi.org/project/lambdaguard/">
    <img src="https://img.shields.io/pypi/v/lambdaguard?logo=python" alt="PyPI Version">
  </a>
  <a href="https://opensource.org/licenses/MIT">
    <img src="https://img.shields.io/badge/License-MIT-green.svg" alt="License MIT">
  </a>
</p>

---

## â“ Why Î»-Guard?

In Gradient Boosting, overfitting often appears **before the validation error rises**.  
By that point, the model is already:

- âœ‚ï¸ Splitting features into extremely fine regions  
- ğŸƒ Fitting leaves supported by very few observations  
- ğŸŒª Sensitive to tiny perturbations  

Itâ€™s **no longer improving predictions**, itâ€™s **memorizing the training dataset**.  
**Î»-Guard detects that moment automatically.**

---

## ğŸ§  Core Intuition

A boosting model learns two things simultaneously:

| Component | Role |
|-----------|------|
| Geometry  | partitions the feature space |
| Predictor | assigns values to each region |

Overfitting occurs when:

*"Geometry keeps growing, but predictor stops extracting real information."*

Î»-Guard measures three key signals:

- ğŸ“¦ **Capacity** â†’ structural complexity  
- ğŸ¯ **Alignment** â†’ extracted signal  
- ğŸŒŠ **Stability** â†’ fragility of predictions

---

## ğŸ§© Representation Matrix

Every tree divides the feature space into **leaves**.  
We record where each observation falls:
Z[i,j] = 1 if sample i falls in leaf j
Z[i,j] = 0 otherwise

- Rows â†’ observations  
- Columns â†’ leaves across all trees  

Think of **Z** as the **representation learned by the ensemble**.

- Linear regression â†’ hat matrix **H**  
- Boosting â†’ representation **Z**

---

## ğŸ“¦ Capacity â€” Structural Complexity

- ğŸ”¹ Low C â†’ few effective regions  
- ğŸ”¹ High C â†’ model fragments space  

Late-stage boosting **increases C quickly**, often without improving predictions.

---

## ğŸ¯ Alignment â€” Useful Information

- ğŸ”¹ High A â†’ trees add real predictive signal  
- ğŸ”¹ Low A â†’ trees mostly refine boundaries  

*"After some trees, alignment saturates."*  
Boosting continues **growing structure** even if prediction stops improving.

---

## ğŸŒŠ Stability â€” Sensitivity to Perturbations

- ğŸ”¹ Low S â†’ smooth, robust model  
- ğŸ”¹ High S â†’ brittle, sensitive model  

**Stability is the first signal to explode during overfitting.**

---

## ğŸ”¥ The Overfitting Index Î»

| Situation | Î» |
|-----------|---|
| Compact structure + stable predictions | low |
| Many regions + weak signal | high |
| Unstable predictions | very high |

**Interpretation:** measures how much structural complexity is wasted.  
Normalized Î» âˆˆ [0,1] can be used to **compare models**.


## ğŸ§ª Structural Overfitting Test

Detect if a few training points dominate the model using **approximate leverage**:
H_ii â‰ˆ Î£_trees (learning_rate / leaf_size)
T1 = mean(H_ii) # global complexity
T2 = max(H_ii)/mean(H_ii) # local memorization


**Bootstrap procedure:**

1. Repeat B times: resample training data, recompute T1 & T2  
2. Compute p-values:  
   - p1 = P(T1_boot â‰¥ T1_obs)  
   - p2 = P(T2_boot â‰¥ T2_obs)  

Reject structural stability if:

p1 < Î± OR p2 < Î±


---

## ğŸ“Š What Î»-Guard Distinguishes

| Regime | Meaning |
|--------|---------|
| âœ… Stable | smooth generalization |
| ğŸ“ˆ Global overfitting | too many effective parameters |
| âš ï¸ Local memorization | few points dominate |
| ğŸ’¥ Extreme | interpolation behavior |

---

## ğŸ§­ When to Use

- Monitor boosting during training  
- Hyperparameter tuning  
- Small datasets (no validation split)  
- Diagnose late-stage performance collapse

---

## âš™ï¸ Installation

Install via GitHub:

```bash
pip install git+https://github.com/faberBI/lambdaguard.git

from sklearn.ensemble import GradientBoostingRegressor
from lambdaguard.ofi import overfitting_index
from lambdaguard.lambda_guard import lambda_guard_test, interpret
from lambdaguard.cusum import detect_structural_overfitting_cusum_robust
import pandas as pd

# Fit a model
model = GradientBoostingRegressor(n_estimators=50, max_depth=3)
model.fit(X_train, y_train)

# Compute Overfitting Index
ofi_res = overfitting_index(model, X_train, y_train)

# Lambda-guard test
lg_res = lambda_guard_test(model, X_train)
print(interpret(lg_res))

# CUSUM-based detection
df = pd.DataFrame([
    {"model": "GBR", "n_estimators": 50, "max_depth": 3, "A": 0.8, "OFI_norm": 0.2},
    {"model": "GBR", "n_estimators": 100, "max_depth": 5, "A": 0.85, "OFI_norm": 0.3},
])
cusum_res = detect_structural_overfitting_cusum_robust(df, model_name="GBR")

```

## ğŸ“œ Citation

If you use **Î»-Guard** in your research or projects, please cite the following:

**Fabrizio Di Sciorio, PhD**  
*Universidad de Almeria â€” Business and Economics Department*  
> "Î»-Guard: Structural Overfitting Detection for Gradient Boosting Models"  

